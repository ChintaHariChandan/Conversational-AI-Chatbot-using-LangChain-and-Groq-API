# Conversational-AI-Chatbot-using-LangChain-and-Groq-API
An interactive and intelligent AI Chatbot built with LangChain, Groq API, and Python (Jupyter Notebook). This project demonstrates how to integrate Large Language Models (LLMs) into a conversational chatbot pipeline, with support for memory, prompts, and customizable model backends.

üß© Features  
‚úÖ Built with LangChain for modular LLM integration  
‚úÖ Uses Groq API for ultra-fast inference  
‚úÖ Memory-enabled ‚Äî retains context across turns  
‚úÖ Clean and extensible Jupyter Notebook structure  
‚úÖ Can be adapted for real-world applications (support, teaching, assistants)  

üõ†Ô∏è Tech Stack
| Component      | Technology         |
| -------------- | ------------------ |
| Language       | Python 3.10+       |
| Framework      | LangChain          |
| Model Provider | Groq (Llama Model) |
| Interface      | Jupyter Notebook   |
| Environment    | Conda / Virtualenv |

### üîê API Key Setup
This project uses the Groq API for LLM access.

To test it yourself:
1. Create a free Groq account ‚Üí [https://console.groq.com](https://console.groq.com)
2. Generate an API key.
3. Set it as a system environment variable:
   - **Windows (CMD):**
     ```bash
     setx GROQ_API_KEY "your_api_key_here"
     ```
   - **Mac/Linux:**
     ```bash
     export GROQ_API_KEY="your_api_key_here"
     ```
4. Restart Jupyter Notebook and run the chatbot.

